\chapter{Test Plan} \label{Chp:TestPlan}

The results of the software is verified by means of

\begin{itemize}
\item Unit testing at the level of functions, such as reading and writing of files, and basic testing of the algorithms.
All functions included in \keyw{io.py} and \keyw{kernel.py} are covered by unit tests.
These tests are carried out by means of the \keyw{pytest} framework.
\item Regression tests have been set up to verify that the results of the command line interactive mode (with redirected standard in input for files coming from WAQUA) and the batch mode (with configuration file input for files coming from either WAQUA or \dflowfm) remain unchanged under further code developments.
\end{itemize}

For the verification of \dfastmi four sets of input files for the Nederrijn River have been used:

\begin{enumerate}
\item One set of input files exported from WAQUA via WAQVIEW.
\item One set of WAQUA files converted using \keyw{sim2ugrid.m} to \dflowfm like netCDF files.
\item One set of \dflowfm simulations using the same curvilinear mesh as was used in WAQUA.
\item One set of \dflowfm simulations using a new unstructured mesh.
\end{enumerate}

Each configuration gives slightly different results; for further regression testing in particular the first two and the last one will be used.
For the automated testing, unit tests and regression tests based on known input/output combinations will be used.
These tests will be executed on the original Python code (i.e. in source code form) and to the degree possible on the compiled binaries as well.

\section{Acceptance testing}

In \autoref{Sec:FuncReq} the 12 functional requirements were listed.
They are repeated below and for every requirement it is indicated how it is tested.

\begin{enumerate}
\item This program must give the same results for the same data as WAQMORF.
This is tested by means of a number of comparison studies, and subsequently tested using regression tests.

\item Users must be able to run this program in batch mode from the command line.
This has been implemented as run mode \keyw{--mode batch}.
The old interactive command line mode is also still available as run mode \keyw{--mode cli}.
The proper functioning of these options is tested by means of regression testing.

\item Users must be able to run the analysis based on \dflowfm results.
This is tested by means of regression testing using result files of \dflowfm version X.

\item Users must be able to provide all data via an input file.
This testing is included in the regression testing of the batch mode, and may in the future be included in the gui testing.

\item The input file must be easy to edit for users, i.e.~a text file.
Goes together with the next item.
\item The input file could use the ini-format consistent with \dflowfm input files.
The \dfastmi configuration file is a simple text file in ini-format, or via redirecting "standard in" to read from a plain text file identical to the WAQMORF input.
There are unit and integration tests addressing the reading of the input files.

\item The report output must be a simple text file consistent with WAQMORF.
The report is (in Dutch) identical to report written by WAQMORF except for product name update and minor reformatting.
This is tested by means of comparison studies, and subsequently tested using regression tests.

\item The spatial output must be easy to visualize in common software.
The output is identical to the WAQMORF output (SIMONA box-file) when WAQUA input is used.
The output is in standard netCDF UGRID format when the input is also in standard netCDF UGRID format coming from \dflowfm.
The netCDF UGRID data files are supported by QUICKPLOT and other post-processing environments such as QGIS.

\item The program should read relevant data directly from \dflowfm map-files instead of intermediate XYZ files as required by WAQMORF for SIMONA results.
All quantities previously read from the XYZ files is now read from the \dflowfm map.nc files (unless running in .

\item A simple graphical user interface could support users in process of creating the input file.
The graphical user interface that you get by running \dfastmi in default mode or by explicitly specifying \keyw{--mode gui} has been tested manually as described in \autoref{Sec:GuiTests}.

\item It would be nice if the software would be more generally applicable than just the Dutch rivers.
A rivers configuration file has been introduced to allow the program to be applied to other systems without recompilation.
Reading the rivers configuration is covered by unit tests and it is also part of the regression tests for the overall system.

\item It would be nice if the software would be able to run besides Dutch also in English.
All texts shown by \dfastmi are read from a language configuration file.
An English and a Dutch version of that configuration file are provided.
A most system tests are carried out using the default English configuration, but one test is carried out using the Dutch configuration.
\end{enumerate}

\section{System testing}

The whole system is tested via the command line (entry via \keyw{\_\_main\_\_}) and via Python calls to the \keyw{run} function in the \keyw{cmd} module.
These tests are repeated for the standalone compiled \dfastmi executable.
For the system testing a limited number of regression tests are carried out comparing the latest results against previously accepted results.

Since the testing of the graphical user interface is not included in the automated testing, a test protocol for manual tests has been defined.
These tests are described in the following section.

\subsection{Manual testing of the user interface} \label{Sec:GuiTests}

\subsubsection{Test 1: starting blank}
\subsubsection{Test 2: save default configuration file}
\subsubsection{Test 3: modify settings}
\subsubsection{Test 4: save modified configuration file}
\subsubsection{Test 5: load default configuration file}
\subsubsection{Test 6: load modified configuration file}
\subsubsection{Test 7: run WAQUA analysis}
\subsubsection{Test 8: run \dflowfm analysis}
\subsubsection{Test 9: view manual and about Windows}

\section{Integration testing}

The \keyw{batch} and \keyw{cli} modules build on the functionality of the \keyw{io} and \keyw{kernel} modules to provide the analysis functionality.
The main routines \keyw{batch\_mode} and \keyw{interactive\_mode} are tested at this level via regression tests, the other routines in \keyw{batch} and \keyw{cli} are tested as part of the unit testing.

\section{Unit testing}

Since the modules \keyw{io} and \keyw{kernel} only depend on third party modules, they are ideally suited for unit testing.
Several routines in \keyw{batch} and \keyw{cli} can be addressed by means of unit testing as well.
Unit tests have been set up for most routines in the \keyw{io} and \keyw{kernel} modules, more unit tests should be added for the other modules.

All routines inside \keyw{gui} are interacting with the graphical user interface (either by extracting data from the state of the controls, or by setting the state of the controls).
These routines cannot be tested using the pytest framework, and are therefore tested by means of the manual system tests.

\section{Automated testing}

Automated TeamCity projects will be set up for testing the Python code, for building (and optionally signing of) binaries, and testing of the binaries.
In this way the formal release process can be easily aligned with the other products.
This is ongoing work; the test and build steps are currently run locally.

For all automated unit and regression tests the pytest framework is used.

\begin{Verbatim}
    > conda install pytest
    > pytest
\end{Verbatim}

%-------------------------------
\chapter{Test Report} \label{Chp:TestReport}

The test plan describes manual tests (the graphical user interface tests as part of the system testing) and automated testing (unit and regression testing).

\section{Manual tests}

This section summarizes the results of the manual testing of the graphical user interface.

\begin{tabular}{ll|l}
Test & Description & Success / Comments \\ \hline
1 & starting blank & OK \\
2 & save default configuration file & OK \\
3 & modify settings & OK \\
4 & save modified configuration file & OK \\
5 & load default configuration file & OK \\
6 & load modified configuration file & OK \\
7 & run WAQUA analysis & OK \\
8 & run \dflowfm analysis & OK \\
9 & view manual and about Windows & OK \\
\end{tabular}


\section{Automated tests}

Below a brief pytest report of the automated regression and unit testing is included.
Each period following a module name represents one successful test; failed test would be indicated by an F and a subsequent error report.

\begin{Verbatim}[fontsize=\tiny]
====================================== test session starts ======================================
platform win32 -- Python 3.8.5, pytest-6.1.2, py-1.9.0, pluggy-0.13.1
rootdir: D:\checkouts\D-FAST\D-FAST_Morphological_Impact
collected 65 items

tests\test_batch.py ...                                                                    [  4%]
tests\test_cli.py ..                                                                       [  7%]
tests\test_io.py ........................................                                  [ 69%]
tests\test_kernel.py ....................                                                  [100%]

====================================== 65 passed in 2.23s =======================================
\end{Verbatim}
